{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Deepfake image detection.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "u8Ud_52ukRZC"
      },
      "outputs": [],
      "source": [
        "%%capture\n",
        "\n",
        "##install required packages\n",
        "from os import listdir\n",
        "import os\n",
        "import glob\n",
        "import random\n",
        "import numpy as np\n",
        "import time\n",
        "import pickle\n",
        "\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.layers import *\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras import layers\n",
        "from tensorflow.keras.utils import to_categorical\n",
        "from tensorflow.keras.callbacks import EarlyStopping\n",
        "from tensorflow.keras.callbacks import ModelCheckpoint\n",
        "from tensorflow.keras.utils import plot_model\n",
        "from keras.models import load_model\n",
        "from gc import callbacks\n",
        "\n",
        "import cv2 as cv\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "import matplotlib.image as mpimg\n",
        "import matplotlib.pyplot as plt\n",
        "%matplotlib inline\n",
        "\n",
        "import seaborn as sns\n",
        "from sklearn import metrics\n",
        "from sklearn.metrics import roc_curve\n",
        "from sklearn.metrics import auc\n",
        "from sklearn.metrics import multilabel_confusion_matrix\n",
        "from sklearn.metrics import accuracy_score\n",
        "from sklearn.metrics import classification_report\n",
        "\n",
        "# If you are using Google Drive, mount it to Google Colab\n",
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#If using Google Colab Pro or Pro+, enable GPU and high RAM usage\n",
        "device = 'GPU:0' #'cuda:0'\n",
        "\n",
        "from psutil import virtual_memory\n",
        "\n",
        "gpu_info = !nvidia-smi\n",
        "gpu_info = '\\n'.join(gpu_info)\n",
        "if gpu_info.find('failed') >= 0:\n",
        "  print('Not connected to a GPU')\n",
        "else:\n",
        "  print(gpu_info)\n",
        "\n",
        "print()\n",
        "\n",
        "ram_gb = virtual_memory().total / 1e9\n",
        "print('Your runtime has {:.1f} gigabytes of available RAM\\n'.format(ram_gb))\n",
        "\n",
        "if ram_gb < 20:\n",
        "  print('Not using a high-RAM runtime')\n",
        "else:\n",
        "  print('You are using a high-RAM runtime!')"
      ],
      "metadata": {
        "id": "IIIxhtyuklu-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#display image in multiple color space representations\n",
        "rgb = mpimg.imread('path/to/image/1PCRGAOF7S.jpg')\n",
        "hsv = cv.cvtColor(rgb, cv.COLOR_RGB2HSV_FULL)\n",
        "ycc = cv.cvtColor(rgb, cv.COLOR_RGB2YCrCb)\n",
        "lab = cv.cvtColor(rgb, cv.COLOR_RGB2Lab)\n",
        "\n",
        "plt.figure(figsize=(24,24))\n",
        "components = {\"RGB\": [\"R\", \"G\", \"B\"], \"HSV\": [\"H\", \"S\", \"V\"], \"YCrCb\": [\"Y\", \"Cr\", \"Cb\"], \"LAB\": [\"L\", \"A\", \"B\"]}\n",
        "\n",
        "for i in range(16):\n",
        "\n",
        "  space_nr = i%4\n",
        "\n",
        "\n",
        "  plt.subplot(4,4,i+1)\n",
        "  if i < 4:\n",
        "\n",
        "    space = \"RGB\"\n",
        "\n",
        "    if space_nr == 0:\n",
        "      plt.imshow(rgb[:,:,:])\n",
        "      plt.axis('off')\n",
        "      plt.title(f'{space}', fontsize= 30)\n",
        "\n",
        "    else: \n",
        "      plt.imshow(rgb[:,:,space_nr-1])\n",
        "      plt.axis('off')\n",
        "      plt.title(f'{components[space][space_nr-1]}', fontsize= 30)\n",
        "\n",
        "  elif i <8:\n",
        "\n",
        "      space = \"HSV\"\n",
        "\n",
        "      if space_nr == 0:\n",
        "        plt.imshow(hsv[:,:,:])\n",
        "        plt.axis('off')\n",
        "        plt.title(f'{space}', fontsize= 30)\n",
        "\n",
        "      else: \n",
        "        plt.imshow(hsv[:,:,space_nr-1])\n",
        "        plt.axis('off')\n",
        "        plt.title(f'{components[space][space_nr-1]}', fontsize= 30)\n",
        "\n",
        "  elif i <12:\n",
        "\n",
        "      space = \"YCrCb\"\n",
        "\n",
        "      if space_nr == 0:\n",
        "        plt.imshow(ycc[:,:,:])\n",
        "        plt.axis('off')\n",
        "        plt.title(f'{space}', fontsize= 30)\n",
        "\n",
        "      else: \n",
        "        plt.imshow(ycc[:,:,space_nr-1])\n",
        "        plt.axis('off')\n",
        "        plt.title(f'{components[space][space_nr-1]}', fontsize= 30)\n",
        "\n",
        "  else:\n",
        "      \n",
        "      space = \"LAB\"\n",
        "      \n",
        "      if space_nr == 0:\n",
        "        plt.imshow(lab[:,:,:])\n",
        "        plt.axis('off')\n",
        "        plt.title(f'{space}', fontsize= 30)\n",
        "\n",
        "      else: \n",
        "        plt.imshow(lab[:,:,space_nr-1])\n",
        "        plt.axis('off')\n",
        "        plt.title(f'{components[space][space_nr-1]}', fontsize= 30)"
      ],
      "metadata": {
        "id": "WN5vdvuolR8B"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "######### Only run the first time #########\n",
        "\n",
        "\n",
        "# First, download the the dataset from https://www.kaggle.com/datasets/xhlulu/140k-real-and-fake-faces and https://www.kaggle.com/datasets/hamzaboulahia/hardfakevsrealfaces\n",
        "\n",
        "#train_ds_paths = glob.glob(\"/path/train/*/*.jpg\") #dataset xhlulu\n",
        "#val_ds_paths = glob.glob(\"/path/val/*/*.jpg\") #dataset xhlulu\n",
        "#test_ds_paths = glob.glob(\"/path/test/*/*.jpg\") #dataset xhlulu\n",
        "\n",
        "#test_ds_paths_3_real = glob.glob(\"/path/test3/real/*.jpg\") #dataset hamzaboulahia\n",
        "#test_ds_paths_3_fake = glob.glob(\"/path/test3/fake/*.jpg\") #dataset hamzaboulahia\n",
        "\n",
        "\n",
        "##################\n",
        "# Google Colab retrieves files faster from Google Drive if they are distributed in more subfolders. Therefore, the train, validation and test data are further divided into multiple subfolders. \n",
        "\n",
        "#for dataset_path,name in zip([train_ds_paths, val_ds_paths, test_ds_paths], ['train', 'val', 'test']):\n",
        "#  for subfolder in range(len(dataset_path)//2500):\n",
        "#    paths = dataset_path[subfolder*2500: (subfolder+1)*2500]\n",
        "      \n",
        "    #os.makedirs(f\"/path/{name}/fake/{subfolder}/\")\n",
        "    #os.makedirs(f\"/path/{name}/real/{subfolder}/\")\n",
        "\n",
        "#    for path in paths:\n",
        "#      classification = path.split(\"/\")[7]\n",
        "#      file_name = path.rsplit(\"/\",1)[1]\n",
        "#      os.replace(path, f\"/path/{name}/{classification}/{subfolder}/{file_name}\")\n",
        "\n",
        "###############\n",
        "## first remove badly badly cropped or a grey scale images from dataset\n",
        "## Then, balance the dataset from hamzaboulahia\n",
        "#if len(test_ds_paths_3_fake)>len(test_ds_paths_3_real):\n",
        "#  random.shuffle(test_ds_paths_3_fake)\n",
        "#  for index, path in enumerate(test_ds_paths_3_fake):\n",
        "#    if index < len(test_ds_paths_3_real):\n",
        "#      continue\n",
        "#    else:\n",
        "#      os.remove(path)\n",
        "\n",
        "\n",
        "####################\n",
        "### read the file paths for each set and save them to your directory for fast acces. \n",
        "\n",
        "#train_ds_paths = glob.glob(\"/path/train/*/*/*.jpg\")\n",
        "#val_ds_paths = glob.glob(\"/path/val/*/*/*.jpg\")\n",
        "#test_ds_paths = glob.glob(\"/path/test/*/*/*.jpg\")\n",
        "#test_ds_paths_3 = glob.glob(\"/path/test3/*/*.jpg\")\n",
        "\n",
        "#with open(f'/path/train_ds_paths.pickle', 'wb') as handle:\n",
        "#  pickle.dump(train_ds_paths, handle, protocol=pickle.HIGHEST_PROTOCOL)\n",
        "\n",
        "#with open(f'/path/val_ds_paths.pickle', 'wb') as handle:\n",
        "#  pickle.dump(val_ds_paths, handle, protocol=pickle.HIGHEST_PROTOCOL)\n",
        "#\n",
        "#with open(f'/path/test_ds_paths.pickle', 'wb') as handle:\n",
        "#  pickle.dump(test_ds_paths, handle, protocol=pickle.HIGHEST_PROTOCOL) \n",
        "\n",
        "#with open(f'/path/test2_ds_paths.pickle', 'wb') as handle:\n",
        "#  pickle.dump(test_ds_paths_2, handle, protocol=pickle.HIGHEST_PROTOCOL)\n",
        "\n",
        "#with open(f'/path/test3_ds_paths.pickle', 'wb') as handle:\n",
        "#  pickle.dump(test_ds_paths_3, handle, protocol=pickle.HIGHEST_PROTOCOL)\n"
      ],
      "metadata": {
        "id": "1Ytx8FZdlVF5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "## load paths of images from each data split\n",
        "with open(f'/path/train_ds_paths.pickle', 'rb') as handle:\n",
        "  train_ds_paths = pickle.load(handle)\n",
        "\n",
        "with open(f'/path/val_ds_paths.pickle', 'rb') as handle:\n",
        "  val_ds_paths = pickle.load(handle)\n",
        "\n",
        "with open(f'/path/test_ds_paths.pickle', 'rb') as handle:\n",
        "  test_ds_paths = pickle.load(handle)\n",
        "\n",
        "with open(f'/path/test2_ds_paths.pickle', 'rb') as handle:\n",
        "  test2_ds_paths = pickle.load(handle)\n",
        "\n",
        "with open(f'/path/test3_ds_paths.pickle', 'rb') as handle:\n",
        "  test3_ds_paths = pickle.load(handle)"
      ],
      "metadata": {
        "id": "eb1lx0j3nVL9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#data loader for training and validation\n",
        "\n",
        "def get_label(file_path):\n",
        "    parts = tf.strings.split(file_path, os.path.sep)\n",
        "\n",
        "    if parts[-3]==\"real\":\n",
        "      return 0\n",
        "    \n",
        "    else:\n",
        "      return 1\n",
        "\n",
        "def process_image_rgb(file_path):\n",
        "    label = get_label(file_path)\n",
        "    \n",
        "    image = tf.io.read_file(file_path)\n",
        "    rgb_image = tf.image.decode_jpeg(image)\n",
        "    rgb_image = rgb_image.numpy()\n",
        "\n",
        "    if rgb_image.shape[1]!= image_size:\n",
        "      rgb_image = cv.resize(rgb_image, (image_size, image_size))\n",
        "    rgb_image = np.float32(rgb_image)/255\n",
        "    \n",
        "    return np.float32(rgb_image), np.float32(label)\n",
        "\n",
        "\n",
        "def process_image_hsv(file_path):\n",
        "    label = get_label(file_path)\n",
        "    \n",
        "    image = tf.io.read_file(file_path)\n",
        "    image = tf.image.decode_jpeg(image)  \n",
        "    image = image.numpy()\n",
        "\n",
        "    hsv_image = cv.cvtColor(image, cv.COLOR_RGB2HSV_FULL)\n",
        "    if hsv_image.shape[1]!= image_size:\n",
        "      hsv_image = cv.resize(hsv_image, (image_size, image_size))\n",
        "    hsv_image = hsv_image/255\n",
        "\n",
        "    return np.float32(hsv_image), np.float32(label)\n",
        "\n",
        "def process_image_ycrcb(file_path):\n",
        "    label = get_label(file_path)\n",
        "    \n",
        "    image = tf.io.read_file(file_path)\n",
        "    image = tf.image.decode_jpeg(image)  \n",
        "    image = image.numpy()\n",
        "    \n",
        "    ycrcb_image = cv.cvtColor(image, cv.COLOR_RGB2YCrCb)\n",
        "    if ycrcb_image.shape[1]!= image_size:\n",
        "      ycrcb_image = cv.resize(ycrcb_image, (image_size, image_size))\n",
        "    ycrcb_image = ycrcb_image/255\n",
        "\n",
        "    return np.float32(ycrcb_image), np.float32(label)\n",
        "\n",
        "def process_image_lab(file_path):\n",
        "    label = get_label(file_path)\n",
        "    \n",
        "    image = tf.io.read_file(file_path)\n",
        "    image = tf.image.decode_jpeg(image) \n",
        "    image = image.numpy() \n",
        "    \n",
        "    \n",
        "    lab_image = cv.cvtColor(image, cv.COLOR_RGB2Lab)\n",
        "    if lab_image.shape[1]!= image_size:\n",
        "      lab_image = cv.resize(lab_image, (image_size, image_size))\n",
        "    lab_image = lab_image/255\n",
        "\n",
        "    return np.float32(lab_image), np.float32(label)\n",
        "\n",
        "def process_image_combined(file_path):\n",
        "    label = get_label(file_path)\n",
        "    \n",
        "    image = tf.io.read_file(file_path)\n",
        "    rgb_image = tf.image.decode_jpeg(image) \n",
        "    rgb_image = rgb_image.numpy()\n",
        "\n",
        "    if rgb_image.shape[1]!= image_size:\n",
        "      rgb_image = cv.resize(rgb_image, (image_size, image_size))\n",
        "\n",
        "   \n",
        "    hsv_image = cv.cvtColor(rgb_image, cv.COLOR_RGB2HSV_FULL)\n",
        "    hsv_image = hsv_image/255    \n",
        "    \n",
        "    ycrcb_image = cv.cvtColor(rgb_image, cv.COLOR_RGB2YCrCb)\n",
        "    ycrcb_image = ycrcb_image/255\n",
        "    \n",
        "    lab_image = cv.cvtColor(rgb_image, cv.COLOR_RGB2Lab)\n",
        "    lab_image = lab_image/255\n",
        "    \n",
        "    rgb_image = rgb_image/255\n",
        "\n",
        "    stacked_image = np.array([np.concatenate(x,axis=1) for x in zip(rgb_image, hsv_image, ycrcb_image, lab_image)])\n",
        "\n",
        "    return np.float32(stacked_image), np.float32(label)\n",
        "\n",
        "def set_shape(video, label):\n",
        "\n",
        "  if color_space == \"rgb\" or color_space == \"hsv\" or color_space == \"ycrcb\" or color_space == \"lab\":\n",
        "    video.set_shape((256,256, 3))\n",
        "    label.set_shape([])\n",
        "\n",
        "    return video, label\n",
        "  else:\n",
        "    video.set_shape((256,256, 12))\n",
        "    label.set_shape([])\n",
        "\n",
        "    return video, label\n",
        "\n",
        "def augment(image, label):\n",
        "    \n",
        "    import albumentations as A\n",
        "    transform = A.Compose([\n",
        "        A.HorizontalFlip(p=0.5),\n",
        "        A.Rotate(limit = 10, p = 0.5)])\n",
        "    transformed = transform(image=image)\n",
        "    transformed_image = transformed[\"image\"]\n",
        "\n",
        "\n",
        "    image = tf.image.random_flip_left_right(image)\n",
        "    image = Image.Image.rotate(image, degrees)\n",
        "\n",
        "    return image, label\n",
        "\n",
        "def data_loader (dataset_paths , color_space):\n",
        "  AUTOTUNE = tf.data.experimental.AUTOTUNE\n",
        "\n",
        "  random.shuffle(dataset_paths)\n",
        "\n",
        "  ds = tf.data.Dataset.from_tensor_slices(dataset_paths)\n",
        "  ds = ds.shuffle(batch_size*8, reshuffle_each_iteration=True)\n",
        "\n",
        "  if color_space == \"rgb\":\n",
        "      \n",
        "    ds = ds.map(lambda item: tf.numpy_function(\n",
        "         process_image_rgb, [item], (tf.float32, tf.float32)) ,num_parallel_calls=AUTOTUNE)  \n",
        "  \n",
        "  elif color_space == \"hsv\":\n",
        "\n",
        "    ds = ds.map(lambda item: tf.numpy_function(\n",
        "         process_image_hsv, [item], (tf.float32, tf.float32)) ,num_parallel_calls=AUTOTUNE) \n",
        "\n",
        "  elif color_space == \"ycrcb\":\n",
        "\n",
        "    ds = ds.map(lambda item: tf.numpy_function(\n",
        "         process_image_ycrcb, [item], (tf.float32, tf.float32)) ,num_parallel_calls=AUTOTUNE)     \n",
        "\n",
        "  elif color_space == \"lab\":\n",
        "\n",
        "    ds = ds.map(lambda item: tf.numpy_function(\n",
        "         process_image_lab, [item], (tf.float32, tf.float32)) ,num_parallel_calls=AUTOTUNE) \n",
        "    \n",
        "  else:\n",
        "\n",
        "    ds = ds.map(lambda item: tf.numpy_function(\n",
        "         process_image_combined, [item], (tf.float32, tf.float32)) ,num_parallel_calls=AUTOTUNE) \n",
        "  \n",
        "  ds = ds.map(set_shape)\n",
        "  \n",
        "  ds = ds.batch(batch_size)\n",
        "  ds = ds.prefetch(AUTOTUNE)\n",
        "\n",
        "  return ds\n"
      ],
      "metadata": {
        "id": "Ic_4ci1OnfcU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#data loader for testing\n",
        "\n",
        "def get_label_test(file_path):\n",
        "  labels = np.zeros(len(file_path))\n",
        "  for index, path in enumerate(file_path):\n",
        "    classification = path.split('/')[7]\n",
        "\n",
        "    if classification ==\"real\":\n",
        "      continue\n",
        "    \n",
        "    else:\n",
        "      labels[index]=1\n",
        "\n",
        "  return labels\n",
        "\n",
        "def process_image_rgb_test(file_path):    \n",
        "    image = tf.io.read_file(file_path)\n",
        "    rgb_image = tf.image.decode_jpeg(image)\n",
        "    rgb_image = rgb_image.numpy()\n",
        "\n",
        "\n",
        "    if rgb_image.shape[1]!= image_size:\n",
        "      rgb_image = cv.resize(rgb_image, (image_size, image_size))\n",
        "    rgb_image = np.float32(rgb_image)/255\n",
        "    \n",
        "    return np.float32(rgb_image)\n",
        "\n",
        "def process_image_hsv_test(file_path):  \n",
        "    image = tf.io.read_file(file_path)\n",
        "    image = tf.image.decode_jpeg(image)  \n",
        "    image = image.numpy()\n",
        "\n",
        "    hsv_image = cv.cvtColor(image, cv.COLOR_RGB2HSV_FULL)\n",
        "    if hsv_image.shape[1]!= image_size:\n",
        "      hsv_image = cv.resize(hsv_image, (image_size, image_size))\n",
        "    hsv_image = hsv_image/255\n",
        "\n",
        "    return np.float32(hsv_image)\n",
        "\n",
        "def process_image_ycrcb_test(file_path):\n",
        "    image = tf.io.read_file(file_path)\n",
        "    image = tf.image.decode_jpeg(image)  \n",
        "    image = image.numpy()\n",
        "    \n",
        "    ycrcb_image = cv.cvtColor(image, cv.COLOR_RGB2YCrCb)\n",
        "    if ycrcb_image.shape[1]!= image_size:\n",
        "      ycrcb_image = cv.resize(ycrcb_image, (image_size, image_size))\n",
        "    ycrcb_image = ycrcb_image/255\n",
        "\n",
        "    return np.float32(ycrcb_image)\n",
        "\n",
        "def process_image_lab_test(file_path):\n",
        "    image = tf.io.read_file(file_path)\n",
        "    image = tf.image.decode_jpeg(image) \n",
        "    image = image.numpy() \n",
        "    \n",
        "    lab_image = cv.cvtColor(image, cv.COLOR_RGB2Lab)\n",
        "    if lab_image.shape[1]!= image_size:\n",
        "      lab_image = cv.resize(lab_image, (image_size, image_size))\n",
        "    lab_image = lab_image/255\n",
        "\n",
        "    return np.float32(lab_image)\n",
        "\n",
        "def process_image_combined_test(file_path):\n",
        "    image = tf.io.read_file(file_path)\n",
        "    rgb_image = tf.image.decode_jpeg(image) \n",
        "    rgb_image = rgb_image.numpy()\n",
        "\n",
        "    if rgb_image.shape[1]!= image_size:\n",
        "      rgb_image = cv.resize(rgb_image, (image_size, image_size))\n",
        "\n",
        "\n",
        "    hsv_image = cv.cvtColor(rgb_image, cv.COLOR_RGB2HSV_FULL)\n",
        "    hsv_image = hsv_image/255    \n",
        "    \n",
        "    ycrcb_image = cv.cvtColor(rgb_image, cv.COLOR_RGB2YCrCb)\n",
        "    ycrcb_image = ycrcb_image/255\n",
        "    \n",
        "    lab_image = cv.cvtColor(rgb_image, cv.COLOR_RGB2Lab)\n",
        "    lab_image = lab_image/255\n",
        "\n",
        "    rgb_image = rgb_image/255\n",
        "    \n",
        "    stacked_image = np.array([np.concatenate(x,axis=1) for x in zip(rgb_image, hsv_image, ycrcb_image, lab_image)])\n",
        "\n",
        "    return np.float32(stacked_image)\n",
        "\n",
        "def set_shape_test(video):\n",
        "  if color_space == \"rgb\" or color_space == \"hsv\" or color_space == \"ycrcb\" or color_space == \"lab\":\n",
        "    video.set_shape((256,256, 3))\n",
        "    return video\n",
        "  else:\n",
        "    video.set_shape((256,256, 12))\n",
        "    return video\n",
        "\n",
        "\n",
        "\n",
        "def data_loader_test (dataset_paths , color_space):\n",
        "  AUTOTUNE = tf.data.experimental.AUTOTUNE\n",
        "\n",
        "  ds = tf.data.Dataset.from_tensor_slices(dataset_paths)\n",
        "\n",
        "  if color_space == \"rgb\":\n",
        "      \n",
        "    ds = ds.map(lambda item: tf.numpy_function(\n",
        "         process_image_rgb_test, [item], tf.float32) ,num_parallel_calls=AUTOTUNE) \n",
        "      \n",
        "  elif color_space == \"hsv\":\n",
        "\n",
        "    ds = ds.map(lambda item: tf.numpy_function(\n",
        "         process_image_hsv_test, [item], tf.float32) ,num_parallel_calls=AUTOTUNE) \n",
        "\n",
        "  elif color_space == \"ycrcb\":\n",
        "\n",
        "    ds = ds.map(lambda item: tf.numpy_function(\n",
        "         process_image_ycrcb_test, [item], tf.float32) ,num_parallel_calls=AUTOTUNE)     \n",
        "\n",
        "  elif color_space == \"lab\":\n",
        "\n",
        "    ds = ds.map(lambda item: tf.numpy_function(\n",
        "         process_image_lab_test, [item], tf.float32) ,num_parallel_calls=AUTOTUNE) \n",
        "    \n",
        "  else:\n",
        "\n",
        "    ds = ds.map(lambda item: tf.numpy_function(\n",
        "         process_image_combined_test, [item], tf.float32) ,num_parallel_calls=AUTOTUNE) \n",
        "  \n",
        "  ds = ds.map(set_shape_test)\n",
        "\n",
        "  ds = ds.batch(batch_size)\n",
        "  ds = ds.prefetch(AUTOTUNE)\n",
        "  #ds = ds.cache()\n",
        "\n",
        "  return ds\n"
      ],
      "metadata": {
        "id": "JKvv_M0mnu3E"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#initialize data loader\n",
        "\n",
        "tf.random.set_seed(2022)\n",
        "\n",
        "image_size = 256\n",
        "batch_size = 16\n",
        "color_space = 'rgb'\n",
        "channels = 3\n",
        "\n",
        "train_ds =  data_loader(train_ds_paths, color_space)\n",
        "val_ds =  data_loader(val_ds_paths, color_space)\n",
        "\n",
        "test1_ds =  data_loader_test(test_ds_paths, color_space)\n",
        "test2_ds =  data_loader_test(test2_ds_paths, color_space)\n",
        "test3_ds =  data_loader_test(test3_ds_paths, color_space)\n",
        "\n",
        "test1_labels =  get_label_test(test_ds_paths)\n",
        "test2_labels =  get_label_test(test2_ds_paths)\n",
        "test3_labels =  get_label_test(test3_ds_paths)\n",
        "\n",
        "\n",
        "for image, label in train_ds.take(3):\n",
        "  print(image.shape, label)\n",
        "\n",
        "for image, label in val_ds.take(3):\n",
        "  print(image.shape, label)\n",
        "\n",
        "for image in test1_ds.take(3):\n",
        "  print(image.shape)\n",
        "\n",
        "for image in test3_ds.take(3):\n",
        "  print(image.shape)"
      ],
      "metadata": {
        "id": "B-_xroF7n5YE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def create_CNN_model():\n",
        "    #initiate model\n",
        "    \n",
        "    model = Sequential()\n",
        "    \n",
        "    model.add(Conv2D(512, (3, 3), padding='same',activation = 'relu'))\n",
        "    \n",
        "    model.add(MaxPooling2D((4, 4), padding = \"same\"))\n",
        "    model.add(BatchNormalization())\n",
        "    model.add(Dropout(0.3))\n",
        "\n",
        "    model.add(Conv2D(512, (3, 3), padding='same',activation = 'relu'))\n",
        "    model.add(MaxPooling2D((2, 2),padding = \"same\"))\n",
        "    model.add(BatchNormalization())\n",
        "    model.add(Dropout(0.3))\n",
        "    \n",
        "    model.add(Conv2D(512, (3, 3), padding='same',activation = 'relu'))\n",
        "    model.add(MaxPooling2D((2, 2),padding = \"same\"))\n",
        "    model.add(BatchNormalization())\n",
        "    model.add(Dropout(0.3))\n",
        "    \n",
        "    model.add(Conv2D(512, (3, 3), padding='same',activation = 'relu'))\n",
        "    model.add(MaxPooling2D((2, 2,), padding = \"same\"))\n",
        "    model.add(BatchNormalization())\n",
        "\n",
        "    model.add(Flatten())\n",
        "    \n",
        "    model.add(layers.Dense(512, activation= 'relu'))\n",
        "    model.add(Dropout(0.3))\n",
        "    model.add(layers.BatchNormalization())\n",
        "    model.add(layers.Dense(512, activation= 'relu'))\n",
        "    model.add(Dropout(0.3))\n",
        "    model.add(layers.Dense(512, activation= 'relu'))\n",
        "    model.add(Dropout(0.3))\n",
        "    model.add(layers.Dense(1, activation= 'sigmoid'))\n",
        "  \n",
        "    # Display the models summary.\n",
        "    model.summary()\n",
        "    \n",
        "    return model"
      ],
      "metadata": {
        "id": "2SXvy8W4oBa9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Construct the CNN\n",
        "CNN_model = create_CNN_model()\n",
        "\n",
        "# Add callbacks \n",
        "tensorboard_callback = tf.keras.callbacks.TensorBoard(log_dir= f'/path/history/CNN-{color_space}-history', histogram_freq=1,  write_graph=True, write_images=True)\n",
        "\n",
        "#Add early stopping\n",
        "early_stopping_callback = EarlyStopping(monitor = 'val_loss', patience = 2, mode = 'min', restore_best_weights = True)\n",
        "\n",
        "save_path = \"/path/models/CNN-rgb-{epoch:02d}-{val_loss:.2f}.keras\"\n",
        "save_model = ModelCheckpoint(save_path, monitor='val_loss', verbose=0, save_best_only=False, save_weights_only=False, mode='auto', save_freq='epoch')\n",
        "\n",
        " \n",
        "# Compile the model \n",
        "CNN_model.compile(loss='binary_crossentropy', optimizer = 'Adam', metrics = [\"accuracy\"])\n",
        "\n",
        "configproto = tf.compat.v1.ConfigProto() \n",
        "configproto.gpu_options.allow_growth = True\n",
        "sess = tf.compat.v1.Session(config=configproto) \n",
        "tf.compat.v1.keras.backend.set_session(sess)"
      ],
      "metadata": {
        "id": "_b-0MdUAoLjf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Train model\n",
        "\n",
        "#CNN_model = load_model('/path/models/CNN-ycrcb-06-0.31.keras')\n",
        "\n",
        "CNN_model_training_history = CNN_model.fit(train_ds,  validation_data= val_ds, epochs = 10,   callbacks = [early_stopping_callback, save_model]) \n"
      ],
      "metadata": {
        "id": "mc1VcIG8oiHK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "%%capture\n",
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras import layers\n",
        "from tensorflow.keras import layers\n",
        "\n",
        "import tensorflow_addons as tfa"
      ],
      "metadata": {
        "id": "RYwt0jz8ozea"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# code based on https://github.com/keras-team/keras-io/blob/master/examples/vision/image_classification_with_vision_transformer.py\n",
        "num_classes = 2\n",
        "input_shape = (256, 256, channels)\n",
        "\n",
        "learning_rate = 0.001\n",
        "weight_decay = 0.0001\n",
        "\n",
        "num_epochs = 50\n",
        "image_size = 256 \n",
        "patch_size = 16  \n",
        "num_patches = (image_size // patch_size) ** 2\n",
        "projection_dim = 64\n",
        "num_heads = 8\n",
        "transformer_units = [\n",
        "    projection_dim * 2,\n",
        "    projection_dim,] \n",
        "transformer_layers = 8\n",
        "mlp_head_units = [2048, 2048]  \n",
        "\n",
        "#Implement multilayer perceptron (MLP)\n",
        "def mlp(x, hidden_units, dropout_rate):\n",
        "    for units in hidden_units:\n",
        "        x = layers.Dense(units, activation=tf.nn.gelu)(x)\n",
        "        x = layers.Dropout(dropout_rate)(x)\n",
        "    return x\n",
        "\n",
        "#Implement patch creation as a layer\n",
        "class Patches(layers.Layer):\n",
        "    def __init__(self, patch_size):\n",
        "        super(Patches, self).__init__()\n",
        "        self.patch_size = patch_size\n",
        "\n",
        "    def call(self, images):\n",
        "        batch_size = tf.shape(images)[0]\n",
        "        patches = tf.image.extract_patches(\n",
        "            images=images,\n",
        "            sizes=[1, self.patch_size, self.patch_size, 1],\n",
        "            strides=[1, self.patch_size, self.patch_size, 1],\n",
        "            rates=[1, 1, 1, 1],\n",
        "            padding=\"VALID\",\n",
        "        )\n",
        "        patch_dims = patches.shape[-1]\n",
        "        patches = tf.reshape(patches, [batch_size, -1, patch_dims])\n",
        "        return patches\n",
        "\n",
        "#Implement the patch encoding layer\n",
        "#The PatchEncoder layer will linearly transform a patch by projecting it into a vector of size projection_dim. In addition, it adds a learnable position embedding to the projected vector.\n",
        "\n",
        "class PatchEncoder(layers.Layer):\n",
        "    def __init__(self, num_patches, projection_dim):\n",
        "        super(PatchEncoder, self).__init__()\n",
        "        self.num_patches = num_patches\n",
        "        self.projection = layers.Dense(units=projection_dim)\n",
        "        self.position_embedding = layers.Embedding(\n",
        "            input_dim=num_patches, output_dim=projection_dim\n",
        "        )\n",
        "\n",
        "    def call(self, patch):\n",
        "        positions = tf.range(start=0, limit=self.num_patches, delta=1)\n",
        "        encoded = self.projection(patch) + self.position_embedding(positions)\n",
        "        return encoded\n",
        "\n",
        "def create_vit_classifier():\n",
        "    inputs = layers.Input(shape=input_shape)\n",
        "    # Create patches.\n",
        "    patches = Patches(patch_size)(inputs)\n",
        "    # Encode patches.\n",
        "    encoded_patches = PatchEncoder(num_patches, projection_dim)(patches)\n",
        "\n",
        "    # Create multiple layers of the Transformer block.\n",
        "    for _ in range(transformer_layers):\n",
        "        # Layer normalization 1.\n",
        "        x1 = layers.LayerNormalization(epsilon=1e-6)(encoded_patches)\n",
        "        # Create a multi-head attention layer.\n",
        "        attention_output = layers.MultiHeadAttention(\n",
        "            num_heads=num_heads, key_dim=projection_dim, dropout=0.1\n",
        "        )(x1, x1)\n",
        "        # Skip connection 1.\n",
        "        x2 = layers.Add()([attention_output, encoded_patches])\n",
        "        # Layer normalization 2.\n",
        "        x3 = layers.LayerNormalization(epsilon=1e-6)(x2)\n",
        "        # MLP.\n",
        "        x3 = mlp(x3, hidden_units=transformer_units, dropout_rate=0.1)\n",
        "        # Skip connection 2.\n",
        "        encoded_patches = layers.Add()([x3, x2])\n",
        "\n",
        "    # Create a [batch_size, projection_dim] tensor.\n",
        "    representation = layers.LayerNormalization(epsilon=1e-6)(encoded_patches)\n",
        "    representation = layers.Flatten()(representation)\n",
        "    representation = layers.Dropout(0.5)(representation)\n",
        "    # Add MLP.\n",
        "    features = mlp(representation, hidden_units=mlp_head_units, dropout_rate=0.5)\n",
        "    # Classify outputs.\n",
        "    #logits = layers.Dense(num_classes)(features)\n",
        "    outputs = layers.Dense(1, activation= 'sigmoid')(features)\n",
        "    # Create the Keras model.\n",
        "    model = keras.Model(inputs=inputs, outputs=outputs)#logits\n",
        "    \n",
        "    model.summary()\n",
        "\n",
        "    return model"
      ],
      "metadata": {
        "id": "j8TuRboco3Jr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Display image patches for the ViT\n",
        "plt.figure(figsize=(4, 4))\n",
        "\n",
        "image=mpimg.imread('/path/1PCRGAOF7S.jpg')\n",
        "\n",
        "plt.imshow(image.astype(\"uint8\"))\n",
        "plt.axis(\"off\")\n",
        "\n",
        "resized_image = tf.image.resize(\n",
        "    tf.convert_to_tensor([image]), size=(256, 256)\n",
        ")\n",
        "patches = Patches(patch_size)(resized_image)\n",
        "print(f\"Image size: {image_size} X {image_size}\")\n",
        "print(f\"Patch size: {patch_size} X {patch_size}\")\n",
        "print(f\"Patches per image: {patches.shape[1]}\")\n",
        "print(f\"Elements per patch: {patches.shape[-1]}\")\n",
        "\n",
        "n = int(np.sqrt(patches.shape[1]))\n",
        "plt.figure(figsize=(4, 4))\n",
        "for i, patch in enumerate(patches[0]):\n",
        "    ax = plt.subplot(n, n, i + 1)\n",
        "    patch_img = tf.reshape(patch, (patch_size, patch_size, 3))\n",
        "    plt.imshow(patch_img.numpy().astype(\"uint8\"))\n",
        "    plt.axis(\"off\")"
      ],
      "metadata": {
        "id": "kk1s4XbupPEz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Construct the ViT\n",
        "vit_classifier = create_vit_classifier()\n",
        "\n",
        "#construct optimizer\n",
        "optimizer = tfa.optimizers.AdamW(\n",
        "    learning_rate=learning_rate, weight_decay=weight_decay)\n",
        "\n",
        "#compile model\n",
        "vit_classifier.compile(\n",
        "    optimizer=optimizer,\n",
        "    loss='binary_crossentropy',\n",
        "    metrics=[\"accuracy\"])\n",
        "\n",
        "#add callback\n",
        "checkpoint_filepath = \"/path/models/vit-ycrcb/vit2-ycrcb-{epoch:02d}-{val_loss:.2f}.keras\"\n",
        "checkpoint_callback = keras.callbacks.ModelCheckpoint(\n",
        "    checkpoint_filepath,\n",
        "    monitor=\"val_accuracy\",\n",
        "    save_best_only=False,\n",
        "    save_weights_only=True,\n",
        "    mode='auto',\n",
        "    save_freq='epoch')\n",
        "\n",
        "#vit_classifier.load_weights(\"/path/models/vit-ycrcb/vit-ycrcb-20-0.20.keras\")\n",
        "\n",
        "# train model\n",
        "history = vit_classifier.fit(train_ds,\n",
        "    batch_size=batch_size,\n",
        "    epochs=10,\n",
        "    validation_data= val_ds,\n",
        "    callbacks=[checkpoint_callback],)"
      ],
      "metadata": {
        "id": "usDMvJVrpbdT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "epochs10 = [1,2,3,4,5,6,7,8,9,10]\n",
        "epochs20 = [1,2,3,4,5,6,7,8,9,10,11,12,13,14,15,16,17,18,19,20]\n",
        "epochs30 = [1,2,3,4,5,6,7,8,9,10,11,12,13,14,15,16,17,18,19,20,21,22,23,24,25,26,27,28,29,30]\n",
        "\n",
        "#load models for testing\n",
        "cnn_models_rgb = glob.glob('/path/models/cnn-rgb/*.keras')\n",
        "cnn_models_rgb = sorted(cnn_models_rgb, key=lambda x: int(x.split('-')[3]), reverse=False)\n",
        "print(cnn_models_rgb)\n",
        "\n",
        "cnn_models_hsv = glob.glob('/path/models/cnn-hsv/*.keras')\n",
        "cnn_models_hsv = sorted(cnn_models_hsv, key=lambda x: int(x.split('-')[3]), reverse=False)\n",
        "print(cnn_models_hsv)\n",
        "\n",
        "cnn_models_ycrcb = glob.glob('/path/models/cnn-ycrcb/*.keras')\n",
        "cnn_models_ycrcb = sorted(cnn_models_ycrcb, key=lambda x: int(x.split('-')[3]), reverse=False)\n",
        "print(cnn_models_ycrcb)\n",
        "\n",
        "cnn_models_lab = glob.glob('/path/models/cnn-lab/*.keras')\n",
        "cnn_models_lab = sorted(cnn_models_lab, key=lambda x: int(x.split('-')[3]), reverse=False)\n",
        "print(cnn_models_lab)\n",
        "\n",
        "cnn_models_stacked = glob.glob('/path/models/cnn-stacked/*.keras')\n",
        "cnn_models_stacked = sorted(cnn_models_stacked, key=lambda x: int(x.split('-')[3]), reverse=False)\n",
        "print(cnn_models_stacked)\n",
        "\n",
        "\n",
        "vit_models_rgb = glob.glob('/path/models/vit-rgb/*.keras')\n",
        "vit_models_rgb = sorted(vit_models_rgb, key=lambda x: int(x.split('-')[3]), reverse=False)\n",
        "print(vit_models_rgb)\n",
        "\n",
        "\n",
        "vit_models_hsv = glob.glob('/path/models/vit-hsv/*.keras')\n",
        "vit_models_hsv = sorted(vit_models_hsv, key=lambda x: int(x.split('-')[3]), reverse=False)\n",
        "print(vit_models_hsv)\n",
        "\n",
        "vit_models_ycrcb = glob.glob('/path/models/vit-ycrcb/*.keras')\n",
        "vit_models_ycrcb = sorted(vit_models_ycrcb, key=lambda x: int(x.split('-')[3]), reverse=False)\n",
        "print(vit_models_ycrcb)\n",
        "\n",
        "vit_models_lab = glob.glob('/path/models/vit-lab/*.keras')\n",
        "vit_models_lab = sorted(vit_models_lab, key=lambda x: int(x.split('-')[3]), reverse=False)\n",
        "print(vit_models_lab)\n",
        "\n",
        "vit_models_stacked = glob.glob('/path/models/vit-stacked/*.keras')\n",
        "vit_models_stacked = sorted(vit_models_stacked, key=lambda x: int(x.split('-')[3]), reverse=False)\n",
        "print(vit_models_stacked)\n",
        "\n",
        "#scores gathered by cell below\n",
        "cnn_models_rgb_acc    =   [0.787, 0.868, 0.924, 0.924, 0.954, 0.937, 0.963, 0.932, 0.972, 0.961]\n",
        "cnn_models_hsv_acc    =   [0.728, 0.814, 0.856, 0.889, 0.888, 0.910, 0.916, 0.930, 0.940, 0.923]      \n",
        "cnn_models_ycbcr_acc  =   [0.794, 0.834, 0.885, 0.859, 0.955, 0.951, 0.968, 0.970, 0.965, 0.970]        \n",
        "cnn_models_lab_acc    =   [0.744, 0.832, 0.879, 0.920, 0.947, 0.951 ,0.908, 0.906, 0.902, 0.937]\n",
        "\n",
        "cnn_models_rgb_loss   =   [0.506,0.316,0.239,0.187,0.126,0.403,0.297,0.170,0.152,0.273]\n",
        "cnn_models_hsv_loss   =   [0.546,0.410,0.345,0.256,0.265,0.265,0.299,0.491,0.994,0.751] \n",
        "cnn_models_ycbcr_loss =   [0.439,0.382,0.269,0.473,0.149,0.311,0.183,0.131,0.516,0.239]  \n",
        "cnn_models_lab_loss   =   [0.633,0.387,0.482,0.232,0.359,0.136,0.465,1.063,0.593,0.656] \n",
        "\n",
        "cnn_models_rgb_test1  =   [0.788, 0.872, 0.925, 0.924, 0.954, 0.939, 0.963, 0.932, 0.973, 0.964]\n",
        "cnn_models_hsv_test1  =   [0.733, 0.822, 0.860, 0.891, 0.894, 0.915, 0.919, 0.933, 0.942, 0.920] \n",
        "cnn_models_ycbcr_test1=   [0.798, 0.832, 0.886, 0.853, 0.955, 0.953, 0.968, 0.973, 0.965, 0.970]\n",
        "cnn_models_lab_test1  =   [0.743, 0.833, 0.881, 0.918, 0.946, 0.951, 0.907, 0.904, 0.903, 0.940]  \n",
        "\n",
        "vit_models_rgb_acc =  [0.500, 0.732, 0.799, 0.838, 0.867, 0.856, 0.903, 0.900, 0.901, 0.913, 0.925, 0.937, 0.924, 0.930, 0.935, 0.941, 0.910, 0.942, 0.945, 0.914]\n",
        "vit_models_hsv_acc =   [0.629, 0.778, 0.829, 0.853, 0.873, 0.889, 0.825, 0.901, 0.913, 0.9, 0.921, 0.887, 0.927, 0.897, 0.919, 0.93, 0.922, 0.922, 0.936, 0.925]       \n",
        "vit_models_ycbcr_acc = [0.5, 0.697, 0.766, 0.796, 0.805, 0.842, 0.819, 0.862, 0.875, 0.836, 0.858, 0.895, 0.868, 0.88, 0.876, 0.901, 0.857, 0.9, 0.914, 0.921, 0.926, 0.921, 0.869, 0.932, 0.925, 0.925, 0.928, 0.932, 0.922, 0.93]       \n",
        "vit_models_lab_acc =   [0.5, 0.651, 0.74, 0.768, 0.805, 0.795, 0.84, 0.862, 0.871, 0.891, 0.888, 0.892, 0.912, 0.9, 0.903, 0.914, 0.91, 0.899, 0.931, 0.92, 0.886, 0.924, 0.916, 0.917, 0.933, 0.931, 0.903, 0.937, 0.938, 0.919]         \n",
        "\n",
        "vit_models_rgb_loss =   [0.693, 0.536, 0.431, 0.362, 0.329, 0.32, 0.233, 0.238, 0.238, 0.214, 0.201, 0.164, 0.192, 0.184, 0.166, 0.152, 0.222, 0.15, 0.145, 0.21]\n",
        "vit_models_hsv_loss =   [0.649, 0.461, 0.381, 0.338, 0.298, 0.266, 0.378, 0.238, 0.211, 0.241, 0.205, 0.268, 0.186, 0.241, 0.198, 0.17, 0.192, 0.189, 0.163, 0.187]       \n",
        "vit_models_ycbcr_loss =  [0.693, 0.595, 0.494, 0.44, 0.419, 0.36, 0.401, 0.316, 0.302, 0.366, 0.333, 0.26, 0.307, 0.286, 0.288, 0.244, 0.323, 0.24, 0.212, 0.195, 0.185, 0.19, 0.301, 0.178, 0.186, 0.191, 0.175, 0.168, 0.188, 0.179]     \n",
        "vit_models_lab_loss =   [0.694, 0.624, 0.527, 0.48, 0.419, 0.511, 0.364, 0.322, 0.307, 0.262, 0.268, 0.264, 0.221, 0.242, 0.236, 0.212, 0.229, 0.242, 0.175, 0.196, 0.268, 0.192, 0.216, 0.205, 0.177, 0.183, 0.24, 0.161, 0.157, 0.193]   \n",
        "\n",
        "vit_models_rgb_test1  =   [0.5, 0.737, 0.804, 0.84, 0.866, 0.858, 0.905, 0.904, 0.905, 0.913, 0.923, 0.936, 0.924, 0.927, 0.935, 0.943, 0.910, 0.941, 0.943, 0.913] \n",
        "vit_models_hsv_test1 =    [0.627, 0.783, 0.83, 0.854, 0.871, 0.887, 0.829, 0.897, 0.915, 0.901, 0.92, 0.889, 0.927, 0.898, 0.92, 0.929, 0.923, 0.925, 0.935, 0.927] \n",
        "vit_models_ycrcb_test1 = \t[0.5, 0.695, 0.767, 0.797, 0.805, 0.839, 0.819, 0.863, 0.874, 0.832, 0.858, 0.891, 0.865, 0.878, 0.874, 0.902, 0.86, 0.897, 0.913, 0.922, 0.927, 0.923, 0.869, 0.93, 0.928, 0.925, 0.93, 0.934, 0.92, 0.932] \n",
        "vit_models_lab_test1  =   [0.5, 0.655, 0.741, 0.77, 0.805, 0.788, 0.837, 0.86, 0.869, 0.888, 0.884, 0.891, 0.912, 0.902, 0.899, 0.912, 0.907, 0.897, 0.93, 0.925, 0.886, 0.923, 0.918, 0.915, 0.931, 0.934, 0.907, 0.939, 0.937, 0.921]\n"
      ],
      "metadata": {
        "id": "AXuLJwFup8vj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# get validation accuracy and loss\n",
        "acc_val = []\n",
        "loss_val = []\n",
        "for model in cnn_models_rgb:\n",
        "  #vit_classifier.load_weights(model)\n",
        "  #acc = vit_classifier.evaluate(data_loader(test1_ds_paths, color_space))\n",
        "\n",
        "  CNN_model = load_model(model)\n",
        "  acc = CNN_model.evaluate(data_loader(val_ds_paths, color_space))\n",
        "\n",
        "  acc_val.append(round(acc[1],3))\n",
        "  loss_val.append(round(acc[0],3))\n",
        "\n",
        "print(loss_val)\n",
        "print(acc_val)"
      ],
      "metadata": {
        "id": "1GAtjdYbqlHP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#plot validation loss CNN\n",
        "plt.figure(figsize=(4,3), dpi =1200)\n",
        "plt.plot(epochs10[:5],cnn_models_rgb_loss[:5], 'k-' )\n",
        "plt.plot(epochs10[:6],cnn_models_hsv_loss[:6], 'k--')\n",
        "plt.plot(epochs10[:8],cnn_models_ycbcr_loss[:8], 'k-.' )\n",
        "plt.plot(epochs10[:6],cnn_models_lab_loss[:6], 'k:' )\n",
        "\n",
        "plt.ylabel('Loss')\n",
        "plt.xlabel('Epochs')\n",
        "plt.legend(['RGB', 'HSV', 'YCbCr', \"LAB\"], loc='upper right')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "IDxILXtAqnQT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#plot validation loss ViT\n",
        "plt.figure(figsize=(4,3), dpi =1200)\n",
        "plt.plot(epochs20[:19],vit_models_rgb_loss[:19],  'k-' )\n",
        "plt.plot(epochs20[:19],vit_models_hsv_loss[:19],  'k--' )\n",
        "plt.plot(epochs30[:24],vit_models_ycbcr_loss[:24],  'k-.' )\n",
        "plt.plot(epochs30[:25],vit_models_lab_loss[:25],  'k:' )\n",
        "\n",
        "plt.ylabel('Loss')\n",
        "plt.xlabel('Epochs')\n",
        "plt.legend(['RGB' , 'HSV', 'YCbCr', 'LAB'], loc='upper right')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "1pz5-fykrKbn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "##plot validation accuracy CNN\n",
        "plt.figure(figsize=(4,3), dpi =1200)\n",
        "\n",
        "plt.plot(epochs10[:5],cnn_models_rgb_acc[:5], 'k-' )\n",
        "plt.plot(epochs10[:6],cnn_models_hsv_acc[:6], 'k--')\n",
        "plt.plot(epochs10[:8],cnn_models_ycbcr_acc[:8], 'k-.' )\n",
        "plt.plot(epochs10[:6],cnn_models_lab_acc[:6], 'k:' )\n",
        "\n",
        "plt.ylabel('Accuracy')\n",
        "plt.xlabel('Epochs')\n",
        "plt.legend(['RGB' , 'HSV', 'YCbCr', 'LAB'], loc='lower right')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "mwObs5OurSvZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "## plot validation accuracy ViT\n",
        "plt.figure(figsize=(4,3), dpi =1200)\n",
        "\n",
        "plt.plot(epochs20[:19],vit_models_rgb_acc[:19],  'k-' )\n",
        "plt.plot(epochs20[:19],vit_models_hsv_acc[:19],  'k--' )\n",
        "plt.plot(epochs30[:24],vit_models_ycbcr_acc[:24],  'k-.' )\n",
        "plt.plot(epochs30[:25],vit_models_lab_acc[:25],  'k:' )\n",
        "\n",
        "plt.ylabel('Accuracy')\n",
        "plt.xlabel('Epochs')\n",
        "plt.legend(['RGB' , 'HSV', 'YCbCr', 'LAB'], loc='lower right')\n",
        "\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "njKlN6m6ratO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#get labels test sets\n",
        "test1_labels =  get_label_test(test1_ds_paths)\n",
        "test3_labels =  get_label_test(test3_ds_paths)"
      ],
      "metadata": {
        "id": "RW2cZnHYrqIz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#get test scores cnn\n",
        "test_scores_cnn = {}\n",
        "cnn_model =[cnn_models_rgb[4], cnn_models_hsv[5], cnn_models_ycrcb[7], cnn_models_lab[5]]\n",
        "cnn_color_spaces =['rgb', 'hsv', 'ycrcb', 'lab']\n",
        "for index, (model, color_space) in enumerate(zip(cnn_model,cnn_color_spaces )):\n",
        "  print(model)\n",
        "  print(color_space)\n",
        "\n",
        "  color_space = color_space\n",
        "  batch_size = 16\n",
        "  image_size = 256\n",
        "\n",
        "  \n",
        "  CNN_model = load_model(model)\n",
        "\n",
        "  test1_ds =  data_loader_test(test1_ds_paths, color_space)\n",
        "  test3_ds =  data_loader_test(test3_ds_paths, color_space)\n",
        "\n",
        "  test1_labels_pred = CNN_model.predict(test1_ds)\n",
        "  test3_labels_pred = CNN_model.predict(test3_ds)\n",
        "\n",
        "  test_scores_cnn[model]= {}\n",
        "\n",
        "  for j, (true, pred) in enumerate(zip([test1_labels, test3_labels],[test1_labels_pred, test3_labels_pred])):\n",
        "\n",
        "\n",
        "    pred = np.asarray(pred)\n",
        "    pred = np.round(pred)\n",
        "    true = np.asarray(true) \n",
        "\n",
        "    report = classification_report(true, pred, target_names=['Real', 'Fake'], output_dict = True)\n",
        "    acc = round(report[ 'accuracy'],3)\n",
        "    precision =  round(report['Fake']['precision'],3)\n",
        "    recall =  round(report['Fake']['recall'],3)\n",
        "    metrics = [acc, precision, recall]\n",
        "    test_scores_cnn[model][j] = metrics\n",
        "  \n",
        "  print(test_scores_cnn[model])\n",
        "\n",
        "print(test_scores_cnn)\n",
        "\n"
      ],
      "metadata": {
        "id": "j1qVUthdrvc9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Test results CNN\n",
        "CRGB = {0: [0.954, 0.950, 0.959], 1: [0.734, 0.990, 0.472]}\n",
        "CHSV = {0: [0.915, 0.891, 0.945], 1: [0.791, 0.983, 0.593]}\n",
        "CYCbCr={0: [0.973, 0.962, 0.985], 1: [0.644, 0.908, 0.320]}\n",
        "CLAB = {0: [0.951, 0.948, 0.955], 1: [0.644, 0.983, 0.292]}\n",
        "\n",
        "avg_acc_cnn1 = CRGB[0][0] + CHSV[0][0] + CYCbCr[0][0] + CLAB[0][0]\n",
        "avg_prec_cnn1 = CRGB[0][1] + CHSV[0][1] + CYCbCr[0][1] + CLAB[0][1]\n",
        "avg_rec_cnn1 = CRGB[0][2] + CHSV[0][2] + CYCbCr[0][2] + CLAB[0][2]\n",
        "\n",
        "avg_acc_cnn2 = CRGB[1][0] + CHSV[1][0] + CYCbCr[1][0] + CLAB[1][0]\n",
        "avg_prec_cnn2 = CRGB[1][1] + CHSV[1][1] + CYCbCr[1][1] + CLAB[1][1]\n",
        "avg_rec_cnn2 = CRGB[1][2] + CHSV[1][2] + CYCbCr[1][2] + CLAB[1][2]\n",
        "\n",
        "print(round(avg_acc_cnn1/4,3), round(avg_prec_cnn1/4,3), round(avg_rec_cnn1/4,3) )\n",
        "print(round(avg_acc_cnn2/4,3), round(avg_prec_cnn2/4,3), round(avg_rec_cnn2/4,3) )"
      ],
      "metadata": {
        "id": "vYTHRNCGsDtW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#get test scores ViT\n",
        "\n",
        "test_scores_vit = {}\n",
        "vit_model =[vit_models_rgb[18], vit_models_hsv[18], vit_models_ycrcb[23], vit_models_lab[24]]\n",
        "vit_color_spaces =['rgb', 'hsv', 'ycrcb', 'lab']\n",
        "\n",
        "for index, (model, color_space) in enumerate(zip(vit_model, vit_color_spaces)):\n",
        "  print(model)\n",
        "  print(color_space)\n",
        "  batch_size = 16\n",
        "  color_space = color_space\n",
        "  image_size = 256\n",
        "\n",
        "  \n",
        "  vit_classifier.load_weights(model)\n",
        "\n",
        "  test1_ds =  data_loader_test(test1_ds_paths, color_space)\n",
        "  test3_ds =  data_loader_test(test3_ds_paths, color_space)\n",
        "\n",
        "  test1_labels_pred = vit_classifier.predict(test1_ds)\n",
        "  test3_labels_pred = vit_classifier.predict(test3_ds)\n",
        "\n",
        "  test_scores_vit[model]= {}\n",
        "\n",
        "  for j, (true, pred) in enumerate(zip([test1_labels, test3_labels],[test1_labels_pred, test3_labels_pred])):\n",
        "\n",
        "\n",
        "    pred = np.asarray(pred)\n",
        "    pred = np.round(pred)\n",
        "    true = np.asarray(true) \n",
        "\n",
        "    report = classification_report(true, pred, target_names=['Real', 'Fake'], output_dict = True)\n",
        "    acc = round(report[ 'accuracy'],3)\n",
        "    precision =  round(report['Fake']['precision'],3)\n",
        "    recall =  round(report['Fake']['recall'],3)\n",
        "    metrics = [acc, precision, recall]\n",
        "    test_scores_vit[model][j] = metrics\n",
        "  \n",
        "  print(test_scores_vit[model])\n",
        "\n",
        "print(test_scores_vit)"
      ],
      "metadata": {
        "id": "6UT3u1iwr0mm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Test results ViT\n",
        "VRGB = {0: [0.943, 0.946, 0.941], 1: [0.759, 1.0, 0.517]}\n",
        "VHSV = {0: [0.935, 0.954, 0.914], 1: [0.614, 1.0, 0.228]}\n",
        "VYCbCr ={0: [0.930, 0.925, 0.936], 1: [0.705, 1.0, 0.41]}\n",
        "VLAB =  {0: [0.931, 0.924, 0.940], 1: [0.710, 1.0, 0.42]}\n",
        "\n",
        "avg_acc_vit1 = VRGB[0][0] + VHSV[0][0] + VYCbCr[0][0] + VLAB[0][0]\n",
        "avg_prec_vit1 = VRGB[0][1] + VHSV[0][1] + VYCbCr[0][1] + VLAB[0][1]\n",
        "avg_rec_vit1 = VRGB[0][2] + VHSV[0][2] + VYCbCr[0][2] + VLAB[0][2]\n",
        "\n",
        "avg_acc_vit2 = VRGB[1][0] + VHSV[1][0] + VYCbCr[1][0] + VLAB[1][0]\n",
        "avg_prec_vit2 = VRGB[1][1] + VHSV[1][1] + VYCbCr[1][1] + VLAB[1][1]\n",
        "avg_rec_vit2 = VRGB[1][2] + VHSV[1][2] + VYCbCr[1][2] + VLAB[1][2]\n",
        "\n",
        "print(round(avg_acc_vit1/4,3), round(avg_prec_vit1/4,3), round(avg_rec_vit1/4,3) )\n",
        "print(round(avg_acc_vit2/4,3), round(avg_prec_vit2/4,3), round(avg_rec_vit2/4,3) )"
      ],
      "metadata": {
        "id": "VreL4q1Ar_yV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#calculate average accuracy, precision and recall\n",
        "avg_acc_rgb1 = CRGB[0][0] + VRGB[0][0]\n",
        "avg_acc_hsv1 = CHSV[0][0] + VHSV[0][0]\n",
        "avg_acc_ycbcr1 = CYCbCr[0][0] + VYCbCr[0][0]\n",
        "avg_acc_lab1 = CLAB[0][0] + VLAB[0][0]\n",
        "\n",
        "avg_acc_rgb2 = CRGB[1][0] + VRGB[1][0]\n",
        "avg_acc_hsv2 = CHSV[1][0] + VHSV[1][0]\n",
        "avg_acc_ycbcr2 = CYCbCr[1][0] + VYCbCr[1][0]\n",
        "avg_acc_lab2 = CLAB[1][0] + VLAB[1][0]\n",
        "\n",
        "avg_prec_rgb1 = CRGB[0][1] + VRGB[0][1]\n",
        "avg_prec_hsv1 = CHSV[0][1] + VHSV[0][1]\n",
        "avg_prec_ycbcr1 = CYCbCr[0][1] + VYCbCr[0][1]\n",
        "avg_prec_lab1 = CLAB[0][1] + VLAB[0][1]\n",
        "\n",
        "avg_prec_rgb2 = CRGB[1][1] + VRGB[1][1]\n",
        "avg_prec_hsv2 = CHSV[1][1] + VHSV[1][1]\n",
        "avg_prec_ycbcr2 = CYCbCr[1][1] + VYCbCr[1][1]\n",
        "avg_prec_lab2 = CLAB[1][1] + VLAB[1][1]\n",
        "\n",
        "avg_rec_rgb1 = CRGB[0][2] + VRGB[0][2]\n",
        "avg_rec_hsv1 = CHSV[0][2] + VHSV[0][2]\n",
        "avg_rec_ycbcr1 = CYCbCr[0][2] + VYCbCr[0][2]\n",
        "avg_rec_lab1 = CLAB[0][2] + VLAB[0][2]\n",
        "\n",
        "avg_rec_rgb2 = CRGB[1][2] + VRGB[1][2]\n",
        "avg_rec_hsv2 = CHSV[1][2] + VHSV[1][2]\n",
        "avg_rec_ycbcr2 = CYCbCr[1][2] + VYCbCr[1][2]\n",
        "avg_rec_lab2 = CLAB[1][2] + VLAB[1][2]\n",
        "\n",
        "print(round(avg_acc_rgb1/2,3), round(avg_prec_rgb1/2,3), round(avg_rec_rgb1/2,3) )\n",
        "print(round(avg_acc_rgb2/2,3), round(avg_prec_rgb2/2,3), round(avg_rec_rgb2/2,3) )\n",
        "print()\n",
        "print(round(avg_acc_hsv1/2,3), round(avg_prec_hsv1/2,3), round(avg_rec_hsv1/2,3) )\n",
        "print(round(avg_acc_hsv2/2,3), round(avg_prec_hsv2/2,3), round(avg_rec_hsv2/2,3) )\n",
        "print()\n",
        "print(round(avg_acc_ycbcr1/2,3), round(avg_prec_ycbcr1/2,3), round(avg_rec_ycbcr1/2,3) )\n",
        "print(round(avg_acc_ycbcr2/2,3), round(avg_prec_ycbcr2/2,3), round(avg_rec_ycbcr2/2,3) )\n",
        "print()\n",
        "print(round(avg_acc_lab1/2,3), round(avg_prec_lab1/2,3), round(avg_rec_lab1/2,3) )\n",
        "print(round(avg_acc_lab2/2,3), round(avg_prec_lab2/2,3), round(avg_rec_lab2/2,3) )"
      ],
      "metadata": {
        "id": "MOoXbMmQsK3l"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#calculate average accuracy scores of models\n",
        "average_acc1 = ((round(avg_acc_vit1/4,3) + round(avg_acc_cnn1/4,3))/2) \n",
        "average_acc2 = ((round(avg_acc_vit2/4,3) + round(avg_acc_cnn2/4,3))/2)\n",
        "average_drop_acc_models = ((round(avg_acc_vit1/4,3) + round(avg_acc_cnn1/4,3))/2) - ((round(avg_acc_vit2/4,3) + round(avg_acc_cnn2/4,3))/2)\n",
        "print(\"average acc 1\",average_acc1 )\n",
        "print(\"average acc 2\",average_acc2 )\n",
        "print(\"average drop acc models\", round(average_drop_acc_models,3))\n",
        "\n",
        "average_drop_recall_models = ((round(avg_prec_vit1/4,3) + round(avg_prec_cnn1/4,3))/2) - ((round(avg_prec_vit2/4,3) + round(avg_prec_cnn2/4,3))/2)\n",
        "print(\"average incr prec models\", -1*round(average_drop_recall_models,3))\n",
        "\n",
        "average_drop_recall_models = ((round(avg_rec_vit1/4,3) + round(avg_rec_cnn1/4,3))/2) - ((round(avg_rec_vit2/4,3) + round(avg_rec_cnn2/4,3))/2)\n",
        "print(\"average drop rec models\", round(average_drop_recall_models,3))"
      ],
      "metadata": {
        "id": "KT7aEzM-sR6f"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#calculate variance models\n",
        "variance_acc_cnn1 = round(np.var(np.asarray([CRGB[0][0] , CHSV[0][0] , CYCbCr[0][0] , CLAB[0][0]])),6)\n",
        "variance_prec_cnn1 = round(np.var(np.asarray([CRGB[0][1] , CHSV[0][1] , CYCbCr[0][1] , CLAB[0][1]])),6)\n",
        "variance_rec_cnn1 = round(np.var(np.asarray([CRGB[0][2] , CHSV[0][2] , CYCbCr[0][2] , CLAB[0][2]])),6)\n",
        "\n",
        "variance_acc_cnn2 = round(np.var(np.asarray([CRGB[1][0] , CHSV[1][0] , CYCbCr[1][0] , CLAB[1][0]])),6)\n",
        "variance_prec_cnn2 = round(np.var(np.asarray([CRGB[1][1] , CHSV[1][1] , CYCbCr[1][1] , CLAB[1][1]])),6)\n",
        "variance_rec_cnn2 = round(np.var(np.asarray([CRGB[1][2] , CHSV[1][2] , CYCbCr[1][2] , CLAB[1][2]])),6)\n",
        "\n",
        "variance_acc_vit1 = round(np.var(np.asarray([VRGB[0][0] , VHSV[0][0] , VYCbCr[0][0] , VLAB[0][0]])),6)\n",
        "variance_prec_vit1 = round(np.var(np.asarray([VRGB[0][1] , VHSV[0][1] , VYCbCr[0][1] , VLAB[0][1]])),6)\n",
        "variance_rec_vit1 = round(np.var(np.asarray([VRGB[0][2] , VHSV[0][2] , VYCbCr[0][2] , VLAB[0][2]])),6)\n",
        "\n",
        "variance_acc_vit2 = round(np.var(np.asarray([VRGB[1][0] , VHSV[1][0] , VYCbCr[1][0] , VLAB[1][0]])),6)\n",
        "variance_prec_vit2 = round(np.var(np.asarray([VRGB[1][1] , VHSV[1][1] , VYCbCr[1][1] , VLAB[1][1]])),6)\n",
        "variance_rec_vit2 = round(np.var(np.asarray([VRGB[1][2] , VHSV[1][2] , VYCbCr[1][2] , VLAB[1][2]])),6)\n",
        "\n",
        "print(\"variance cnn1\", variance_acc_cnn1 , variance_prec_cnn1, variance_rec_cnn1 )\n",
        "print(\"variance vit1\", variance_acc_vit1 , variance_prec_vit1, variance_rec_vit1 )\n",
        "\n",
        "print()\n",
        "print(\"variance cnn2 \",variance_acc_cnn1 , variance_prec_cnn1, variance_rec_cnn1 )\n",
        "print(\"variance vit2 \",variance_acc_vit2 , variance_prec_vit2, variance_rec_vit2 )"
      ],
      "metadata": {
        "id": "1F8ewgXZsXDu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#calculate and save ROC & AUC scores for CNN\n",
        "cnn_model =[cnn_models_rgb[4], cnn_models_hsv[5], cnn_models_ycrcb[7], cnn_models_lab[5]]\n",
        "cnn_color_spaces =['rgb', 'hsv', 'ycrcb', 'lab']\n",
        "\n",
        "def roc_auc_cnn (models, spaces):\n",
        "  roc_auc= {}\n",
        "\n",
        "  for index, (model, color_space) in enumerate(zip(models,spaces )):\n",
        "    print(model)\n",
        "    print(color_space)\n",
        "    batch_size = 16\n",
        "    color_space = color_space\n",
        "    image_size = 256\n",
        "    \n",
        "    CNN_model = load_model(model)\n",
        "\n",
        "    test1_ds =  data_loader_test(test1_ds_paths, color_space)\n",
        "    test3_ds =  data_loader_test(test3_ds_paths, color_space)\n",
        "\n",
        "    test1_labels_pred = CNN_model.predict(test1_ds)\n",
        "    test3_labels_pred = CNN_model.predict(test3_ds)\n",
        "\n",
        "    roc_auc[index]= {}\n",
        "\n",
        "    for j, (true, pred) in enumerate(zip([test1_labels, test3_labels],[test1_labels_pred, test3_labels_pred])):\n",
        "\n",
        "\n",
        "      roc_auc[index][j] = []\n",
        "\n",
        "      pred = np.asarray(pred)\n",
        "      true = np.asarray(true) \n",
        "\n",
        "      fpr_keras, tpr_keras, thresholds_keras = roc_curve(true, pred)\n",
        "      auc_keras = auc(fpr_keras, tpr_keras)\n",
        "\n",
        "      metrics = [fpr_keras, tpr_keras, auc_keras]\n",
        "      roc_auc[index][j] = metrics\n",
        "\n",
        "  return roc_auc\n",
        "\n",
        "roc_auc_cnn_results = roc_auc_cnn(cnn_model, cnn_color_spaces)\n",
        "\n",
        "with open(f'/content/gdrive/My Drive/thesis_images/auc/roc_auc_cnn_results.pickle', 'wb') as handle:\n",
        "  pickle.dump(roc_auc_cnn_results, handle, protocol=pickle.HIGHEST_PROTOCOL)"
      ],
      "metadata": {
        "id": "0CzIjSs9sn-m"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#calculate and save ROC & AUC scores for ViT\n",
        "\n",
        "vit_model =[vit_models_rgb[18], vit_models_hsv[18], vit_models_ycrcb[23], vit_models_lab[24]]\n",
        "vit_color_spaces =['rgb', 'hsv', 'ycrcb', 'lab']\n",
        "\n",
        "def roc_auc_vit (models, spaces):\n",
        "  roc_auc= {}\n",
        "\n",
        "  for index, (model, color_space) in enumerate(zip(models,spaces )):\n",
        "    print(model)\n",
        "    print(color_space)\n",
        "    batch_size = 16\n",
        "    color_space = color_space\n",
        "    image_size = 256\n",
        "    \n",
        "    vit_classifier.load_weights(model)\n",
        "\n",
        "    test1_ds =  data_loader_test(test1_ds_paths, color_space)\n",
        "    test3_ds =  data_loader_test(test3_ds_paths, color_space)\n",
        "\n",
        "    test1_labels_pred = vit_classifier.predict(test1_ds)\n",
        "    test3_labels_pred = vit_classifier.predict(test3_ds)\n",
        "\n",
        "    roc_auc[index]= {}\n",
        "\n",
        "    for j, (true, pred) in enumerate(zip([test1_labels, test3_labels],[test1_labels_pred, test3_labels_pred])):\n",
        "\n",
        "\n",
        "      roc_auc[index][j] = []\n",
        "\n",
        "      pred = np.asarray(pred)\n",
        "      true = np.asarray(true) \n",
        "\n",
        "      fpr_keras, tpr_keras, thresholds_keras = roc_curve(true, pred)\n",
        "      auc_keras = auc(fpr_keras, tpr_keras)\n",
        "\n",
        "      metrics = [fpr_keras, tpr_keras, auc_keras]\n",
        "      roc_auc[index][j] = metrics\n",
        "\n",
        "  return roc_auc\n",
        "\n",
        "roc_auc_vit_results = roc_auc_vit(vit_model, vit_color_spaces)\n",
        "\n",
        "with open(f'/content/gdrive/My Drive/thesis_images/auc/roc_auc_vit_results.pickle', 'wb') as handle:\n",
        "  pickle.dump(roc_auc_vit_results, handle, protocol=pickle.HIGHEST_PROTOCOL)"
      ],
      "metadata": {
        "id": "qNOqhQMxsu60"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#plot ROC curves and AUCs of CNN and Vit - first test set\n",
        "with open(f'/content/gdrive/MyDrive/thesis_images/auc/roc_auc_cnn_results.pickle', 'rb') as handle:\n",
        "  roc_auc_cnn_results = pickle.load(handle)\n",
        "\n",
        "with open(f'/content/gdrive/MyDrive/thesis_images/auc/roc_auc_vit_results.pickle', 'rb') as handle:\n",
        "  roc_auc_vit_results = pickle.load(handle)\n",
        "\n",
        "plt.figure(figsize=(4,3), dpi =1200)\n",
        "plt.plot(roc_auc_cnn_results[0][0][0], roc_auc_cnn_results[0][0][1], color= 'black', linestyle = '-', label='CNN - RGB (AUC = {:.3f})'.format(roc_auc_cnn_results[0][0][2]))\n",
        "plt.plot(roc_auc_cnn_results[1][0][0], roc_auc_cnn_results[1][0][1], color= 'black', linestyle = '--', label='CNN - HSV (AUC = {:.3f})'.format(roc_auc_cnn_results[1][0][2]))\n",
        "plt.plot(roc_auc_cnn_results[2][0][0], roc_auc_cnn_results[2][0][1], color= 'black', linestyle = '-.', label='CNN - YCbCr (AUC = {:.3f})'.format(roc_auc_cnn_results[2][0][2]))\n",
        "plt.plot(roc_auc_cnn_results[3][0][0], roc_auc_cnn_results[3][0][1], color= 'black', linestyle = ':', label='CNN - LAB (AUC = {:.3f})'.format(roc_auc_cnn_results[3][0][2]))\n",
        "\n",
        "plt.plot(roc_auc_vit_results[0][0][0], roc_auc_vit_results[0][0][1], color= 'navy', linestyle = '-', label='ViT - RGB (AUC = {:.3f})'.format(roc_auc_vit_results[0][0][2]))\n",
        "plt.plot(roc_auc_vit_results[1][0][0], roc_auc_vit_results[1][0][1], color= 'navy', linestyle = '--', label='ViT - HSV (AUC = {:.3f})'.format(roc_auc_vit_results[1][0][2]))\n",
        "plt.plot(roc_auc_vit_results[2][0][0], roc_auc_vit_results[2][0][1], color= 'navy', linestyle = '-.', label='ViT- YCbCr (AUC = {:.3f})'.format(roc_auc_vit_results[2][0][2]))\n",
        "plt.plot(roc_auc_vit_results[3][0][0], roc_auc_vit_results[3][0][1], color= 'navy', linestyle = ':', label='ViT - LAB (AUC = {:.3f})'.format(roc_auc_vit_results[3][0][2]))\n",
        "\n",
        "\n",
        "plt.plot([0, 1], [0, 1], color='silver', lw=2, linestyle='-')\n",
        "plt.xlabel('False positive rate')\n",
        "plt.ylabel('True positive rate')\n",
        "plt.legend(loc='best')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "reKg17O8s0jV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#plot ROC curves and AUCs of CNN and Vit - second test set\n",
        "\n",
        "plt.figure(figsize=(4,3), dpi =1200)\n",
        "\n",
        "plt.plot(roc_auc_cnn_results[0][1][0], roc_auc_cnn_results[0][1][1], color= 'black', linestyle = '-', label='CNN - RGB (AUC = {:.3f})'.format(roc_auc_vit_results[0][1][2]))\n",
        "plt.plot(roc_auc_cnn_results[1][1][0], roc_auc_cnn_results[1][1][1], color= 'black', linestyle = '--', label='CNN - HSV (AUC = {:.3f})'.format(roc_auc_vit_results[1][1][2]))\n",
        "plt.plot(roc_auc_cnn_results[2][1][0], roc_auc_cnn_results[2][1][1], color= 'black', linestyle = '-.', label='CNN - YCbCr (AUC = {:.3f})'.format(roc_auc_vit_results[2][1][2]))\n",
        "plt.plot(roc_auc_cnn_results[3][1][0], roc_auc_cnn_results[3][1][1], color= 'black', linestyle = ':', label='CNN - LAB (AUC = {:.3f})'.format(roc_auc_vit_results[3][1][2]))\n",
        "\n",
        "plt.plot(roc_auc_vit_results[0][1][0], roc_auc_vit_results[0][1][1], color= 'navy', linestyle = '-', label='ViT - RGB (AUC = {:.3f})'.format(roc_auc_vit_results[0][1][2]))\n",
        "plt.plot(roc_auc_vit_results[1][1][0], roc_auc_vit_results[1][1][1], color= 'navy', linestyle = '--', label='ViT - HSV (AUC = {:.3f})'.format(roc_auc_vit_results[1][1][2]))\n",
        "plt.plot(roc_auc_vit_results[2][1][0], roc_auc_vit_results[2][1][1], color= 'navy', linestyle = '-.', label='ViT - YCbCr (AUC = {:.3f})'.format(roc_auc_vit_results[2][1][2]))\n",
        "plt.plot(roc_auc_vit_results[3][1][0], roc_auc_vit_results[3][1][1], color= 'navy', linestyle = ':', label='ViT - LAB (AUC = {:.3f})'.format(roc_auc_vit_results[3][1][2]))\n",
        "\n",
        "\n",
        "plt.plot([0, 1], [0, 1], color='silver', lw=2, linestyle='-')\n",
        "plt.xlabel('False positive rate')\n",
        "plt.ylabel('True positive rate')\n",
        "plt.legend(loc='best')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "DJjsgUuKs94f"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#calculate average auc\n",
        "average_auc1 = round((roc_auc_cnn_results[0][0][2] + roc_auc_cnn_results[1][0][2] + roc_auc_cnn_results[2][0][2] + roc_auc_cnn_results[3][0][2] + roc_auc_vit_results[0][0][2] + roc_auc_vit_results[1][0][2] + roc_auc_vit_results[2][0][2] + roc_auc_vit_results[3][0][2])/8,3)\n",
        "average_auc2 = round((roc_auc_cnn_results[0][1][2] + roc_auc_cnn_results[1][1][2] + roc_auc_cnn_results[2][1][2] + roc_auc_cnn_results[3][1][2] + roc_auc_vit_results[0][1][2] + roc_auc_vit_results[1][1][2] + roc_auc_vit_results[2][1][2] + roc_auc_vit_results[3][1][2])/8,3)\n",
        "\n",
        "print(\"auc test 1:\", average_auc1)\n",
        "print(\"auc test 2:\", average_auc2)"
      ],
      "metadata": {
        "id": "a0esXdrytGBH"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}